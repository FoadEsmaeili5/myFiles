---
title: انتخاب مدل
author: Foad Esmaeili
date: '2020-06-01'
slug: ''
categories:
  - R
tags:
  - R Markdown
---


<div dir = 'rtl'>

# انتخاب مدل

در فصل 5 کتاب رگرسیون 1 به روشهای انتخاب مدل مانند روشهای پیشرو، پسرو و گام به گام پرداخته شده که همه ی این روشها برای انتخاب بهترین زیر مدل از مدل کامل 
که به صورت زیر است می باشد.





$$y = X_k \beta_k + \epsilon = X_p \beta_p + X_r \beta_r + \epsilon $$

- که در آن y بردار مشاهدات است که دارای nمشاهده است

- r = k-p

 همانطور که واضح است در فرمول بالا:
میتوان زیر مدل هایی برای رگرسیون چند گانه محاسبه کرد 

در این فصل میخواهیم زیر مدل ها را بر اساس معیار ها و روشهای دیگری انتخاب کنیم

### انتخاب مدل براساس معیار های اطلاع


این کمیت به طور معمول بر اساس تابع درستنمایی و تداد پارامتر های مدل بیان می شود.
بر اساس این دو شاخص هر مدلی که دارای درستنمایی بیشتر و تعداد متغیر کمتر باشد مدل بهتری است.

## معیار آکائیک
فرمول آن به شرح زیر است:

$$AIC = n log(\frac{SSE}{n}) + 2p$$
<p font-color = 'red'>
نکته:
در صورتی که تعداد نمونه کوچک باشد و یا آنکه تعداد پارامتر های ممدل نسبت به n زیاد باشد
$\frac{n}{p+2}\leq 40$
توصیه میشود که از معیار آکائیک اصلاح شده استفاده شود.
</p>

$$AIC_c = AIC + \frac{2(p+2)(p+3)}{n-p-1}$$

<p font-color = 'blue'>
نکته: زمانی که 
$n\to \infty$
 این دو معیار معادل هم هستند.
</p>

<p font-color = 'blue'>
 نکته: 
 هرچه قدر معیار AIC کمتر باشد مدل بهتر تر است
</p>


## معیار بیزی 
 فرمول آن به شرح زیر است:
 
 $$BIC = n\ log(\frac{SSE}{n}) + p\ log(n)$$
 
<p font-color = 'blue'>
هر چه قدر که معیار BIC
کمتر ترباشد مدل، مدل بهتر تری است.
</p>

<p class = 'mynotes'>
نکته: در به کار گیری مدل های AICو BIC
بهتر است که مدل های مقایسه، رابطه ای به اصطلاح آشیانه ای داشته باشند. یعنی
یکی از دو مدل زیر مدل دیگری باشد.
</p>


##  معیار $C_p$ مالوس
 این معیار برآوردی از میانگین توان دوم خطای استاندارد شده کل است.
 
 $$C_p  = \frac{SSE}{\hat{\sigma^2}}-n+2p$$
 با توجه به اینکهه این معیار برآورد یک ملاک خطا است مدلی که دارای $C_p$
 کمتری است مدل بهتری می باشد.
 


در نمودار $C_p$
مالوس مدل مناسب دارای دو ویژگی است:

- هر چه مقدار آماره $C_p$ کمتر باشد مدل مناسب تر است
- هر چه قدر مقدار آماره $C_p$
به $p$
نزدیک تر باشد، مدل اریبی کمتری دارد.



 
 
 
از مثال سیمان کتاب رگرسیون خطی استفاده میکنم برای این ارائه

</div>

```{r echo=FALSE,tidy=TRUE}
library(MASS)
data("cement")
knitr::kable(cement)
```

<div dir = "rtl">

برای داده های جدول بالا معیار های $AIC$و $BIC$و $C_p$
را برای مدل های زیر محاسبه میکنیم.

مدل 1:
$$y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \epsilon$$

مدل 2:

$$y = \beta0 + \beta_2 x_2 + \beta_3 x_3 + \beta_4 x_4 + \epsilon$$

</div>

<div dir = "lrt">

```{r}
fit <- lm(y~., data = cement)
aic1 <- AIC(update(fit, .~.-x4))
aic2 <- AIC(update(fit, .~.-x1))
bic1 <- BIC(update(fit, .~.-x4))
bic2 <- BIC(update(fit, .~.-x1))
```

</div>

<div dir = "rtl">

برای محاسبه ی معیار $C_p$مالوس به صورت زیر عمل میکنیم.

</div>

<div dir = 'lrt'>

```{r}
av1 <- anova(update(fit, .~.-x4))

av2 <- anova(update(fit,.~.-x1))

mse <- anova(fit)[5,3]
sse1 <- av1[4,2]
sse2 <- av2[4,2]

cp1 <- sse1/mse-nrow(cement) + 2*(ncol(cement) - 1)
cp2 <- sse2/mse-nrow(cement) + 2*(ncol(cement) - 1)
```


```{r,echo = FALSE}
knitr::kable(data.frame(model = c(1,2),AIC = c(aic1,aic2),BIC = c(bic1,bic2),Cp = c(cp1,cp2)))

```

</div>

<div dir = "rtl">

اما روشی که در رگرسیونی 1 یادگرفتیم در باره ی انتخاب دستی متغیر ها:

</div>

<div dir = 'lrt'>

```{r}
summary(fit)
summary(fit2 <- update(fit,.~.-x3))
summary(fit2 <- update(fit2,.~.-x4))
aic3 <- AIC(fit2)
bic3 <- BIC(fit2)
cp3 <- anova(fit2)[3,2]/mse-nrow(cement) + 2*(ncol(cement)-1)
```

```{r echo=TRUE}
knitr::kable(data.frame(model = c(1,2,3),AIC = c(aic1,aic2,aic3),BIC = c(bic1,bic2,bic3),Cp = c(cp1,cp2,cp3)))
```

```{r}
library(leaps)

l <- regsubsets(y~.,data = cement,intercept = TRUE,nbest = 6) # maximum size for subset is select 2 from 4 which is 6
plot(l,scale = "Cp")# bic Cp adjr2 r2
```

</div>

<div dir = "rtl">

با توجه به اینکه بیشترین زیر مجموعه انتخاب دو از 4 است که برابر 6 می باشد مقدار nbest را برابر 
6 قرار داده ایم تا همه ی مدل ها را نشان دهد.

## انتخاب مدل با روش اعتبار سنجی (cross validation)
در این روش در اصل می آییم داده ها را به عنوان مثال اگه 100 مشاهده است به صورت تصادفی  به ده مشاهده ده تایی تقسیم میکنیم.

در مرحله ی اول از 9 دسته ی اول برای آموزش مدل استفاده میکنیم و مدل را میسازیم و دسته ی دهم را به عنوان دسته ی آزمایشی وارد میکنیم و خطای $E_1$
را بدست می آوریم
در مرحله ی دوم هشت دسته ی اول و دسته ی دهم را انتخاب میکنیم و با آن مدل را آموزش میدهیم و با استفاده از دسته ی نهم که برای آزمایش مدل نگه داشتیم را با استفاده از مدل پیش بینی میکنیم و خطای آن را محاسبه میکنیم و به عنوان $E_2$
در نظر میگیریم.

اینکار را تا جایی ادامه می دهیم که همه ی دسته ها به عنوان داده ی آزمایشی در نظر گرفته شده باشند 
در آخر میانگین خطا ها را محاسبه میکنیم

هر مدلی که میانگین خطای کمتری داشته باشد را  به عنوان مدل نهایی در نظر می گیریم.

$$E_i = \frac{1}{len(F_i)}\sum_{i=F_j}(y_j - \hat{y_j})^2$$
$$Mean\ Error = \frac{1}{k}\sum_{i=1}^{k}E_i$$

</div>

<div dir = 'lrt'>

```{r}
library(DAAG)
CVlm(fit,data = cement,m = 3)
fit2 <- update(fit,.~.-x3)
CVlm(fit2,data = cement,m = 3)
```

</div>

<div dir = "rtl">

## آماره پرس
یک حالت خاص از ملاک اعتبار سنجی متقابل آماره ی مجموع توان دوم پیش بینی پرس است.

آماره ی پرس همان ملاک اعتبار سنجی n گانه است،
که داده ها را به صورت 
$\{1\}\cup \{2\} \cup ...\cup\{n\}$
افراض میکند.

برای محاسبه ی آماره ی پرس برای یک مجموعه که دارای n 
مشاهده است در هر مرحله یکی از مشاهده ها رو از داده ها خارج میکنه و با n-1
مشاهده ی دیگه مدل رو برازش میدهد و با مدل برازش داده شده مشاهده ای که حذف شده بود را پیش بینی میکند
اگر مشاهده ی i ام را با 
$\hat{y_i}; i=1,2,3,...$
نمایش دهیم 
در این صورت آماره ی پرس به صورت زیر قابل محاسبه خواهد بود.

$$PRESS = \sum_{i=1}^{n}{(y_i - \hat{y_{-i}})^2}$$
یک ملاک جایگزین برای ضریب تعیین بر اساس آماره ی پرس، آماره ی ضریب تعیین پیش بینی هست که به صورت زیر تعریف میشود:

$$P^2 = 1- \frac{PRESS}{S_{yy}}$$
در واقع $P^2$
نشان دهنده ی مقدار پراکندگی توضیح داده شده توسط مدل در پیش بینی یک مشاهده ی جدید است.
براساس این معیار هر چه مقدار$P^2$ بیشتر باشد مدل، مدل بهتری است.

برای محاسبه ی آماره ی پرس و ملاک های مرتبط از تابع PRESS
در بسته ی qpcR
استفاده میکنیم.

</div>

<div dir = 'lrt'>

```{r message=FALSE}
data("cement",package = "MASS")
fit <- lm(y~x1+x2+x3+x4, data = cement)
#
l <- regsubsets(y~.,data = cement,intercept = TRUE,nbest = 6)
plot(l,scale = 'adjr2')
```

</div>

<div dir = "rtl">

با توجه به نمودار بالا سه مدل پیشنهاد میشود

- حذف x3 از مدل

- حذف x4 از مدل

- حذف x2 از مدل

حال با استفاده از آماره ی پرس آن مدلی که کمتری آماره ی پرس را داشت به عنوان مدل نهایی انتخاب میکنیم.

</div>

<div dir = 'lrt'>

```{r message=FALSE}
library(qpcR)
attach(cement)
(press1 <- qpcR::PRESS(fit))

(press2 <- PRESS(update(fit,.~.-x3)))
 
(press3 <- PRESS(update(fit,.~.-x4)))
 
(press4<- PRESS(update(fit,.~.-x2)))

detach(cement)
```

</div>

<div dir = "rtl">

با توجه به نتایج بدست آمده.
مدلی که حذف x3 را در خود دارد
به عنوان بهترین مدل شناخته میشود و با توجه به ضریب تعیین پیش بینی که برابر `r press3$P.square` شده
میتوان گفت که 
این مدل حدود `r round(press3$P.square*100)`
درصد از پراکندگی  را در پیش بینی یک مشاهده ی جدید توضیح دهد.

## انتخاب متغیر با به کارگیری روش لاسو
### LASSO REGRESSION::


این روش یک حلت خاص از رگرسیون حریمه است. در روش کمترین توان دوم خطای جریمه به جای کمینه کردن
$S(\beta) = (y-X\beta)'(y-X\beta)$
مجموع توان دوم خطای خطای جریمه شده را که به صورت زیر تعریف میشود کمینه میکنیم.

$$S(\beta,\alpha) = (y-X\beta)'(y-X\beta) + \alpha P(\beta)$$
در رگرسیون لاسو که حالت خاصی از رگرسیون بریج ($P(\beta) = \sum_{i=1}^{p}|\beta_i|^q$)
است، در این حالت
$q=1$
می باشد.

بنابراین در روش لاسو برآورد ضریب های 
$\beta$
از کمینه کردن مجموع توان دوم خطای جریمه شده با تابع جریمه ی 
$\sum_{i=1}^p|\beta_i|$
به صورت زیر بدست می آید.

$$S(\beta,\alpha) = (y-X\beta)'(y-X\beta) + \alpha \sum_{i=0}^p|\beta_i|$$
این مساله ی بهینه سازی رو نمیتوان به صورت جبری حل کرد لذا با استفاده از روشهای عددی و برنامه ریزی خطی بدست می آورند.





یکی از روشهای یافتن برآورد لاسو با روش رگرسیون کم ترین زاویه، لارس ارائه داده اند.

برای برآورد ضرایب لاسو شبیه به روش رگرسیونی پیشرو عمل میکنیم فقط با یک تفاوت که در ادامه شرح داده می شود:


ابتدا همه ی ضرایب را برابر صفر در نظر میگیریم.
و $r = y-\bar{y}$

- آن متغیری که بیشترین همبستگی را با 
باقی مانده ی مدل دارد یعنی r
را به عنوان متغیر ورودی در نظر میگیریم
سپس مدل را برازش میدهیم
(فرض کنیم متغیر $l$ ام بیشترین همبستگی را با باقی مانده ی مدل داشته باشد)

- مدل رگرسیونی جدید را به صورت زیر برازش میدهیم
 $\hat{y} = \beta_0 + \beta_lX_l$
 سپس باقی مانده ی این مدل را محاسبه میکنیم.
 
 $r = y - \hat{y}$
 
 
- آن متغیر دیگری که بیشترین همبستگی را با باقی مانده ی مدل جدید دارد را به عنوان کاندید ورودی برای متغیر جدید در نظر میگیریم.

و اینکارا انقدر ادامه میدهیم تا همه ی متغیر ها وارد مدل شوند.

</div>

<div dir = 'lrt'>

```{r}
data("cement",package = "MASS")
library(lars)
#install.packages("lars")
cement2 <- sapply(cement, scale) # centring.
X = as.matrix(cbind(1,cement2[,1:4]))
(l <- lars(X,cement2[,5],type = "lasso"))
coef(l)
```

</div>

<div dir = "rtl">

همانطور که در ضرایب برآورد شده مشاهده میشود 
ابتداهیچ متغیری در مدل وجود ندارد 
سپس متغیر x4
که بیشترین همبستگی را با متغیر وابسته داشت وارد مدل میشودو بعد
x1
که بیشترین همبستگی با باقی مانده ی مدل
$y = \beta_1X1$
دارد وارد مدل میشود و اینکار آنقدر ادامه پیدا میکند که همه ی متغیر ها وارد مدل میشوند.

ولی نکته ای که وجود دارد این هست که کدام یکی از این مراحل بهترین برازش را نشان می دهد؟
برای اینکار از خروجی تابع lars 
یک summary
میگیریم

</div>

<div dir = 'lrt'>

```{r}
summary(l)
plot(l)
plot(l,plottype = "Cp")
```

</div>

<div dir = "rtl">

همانطور که در خروجی تابع دیده میشود 
و همانطور که در اول همین فصل هم گفته شده 
آن مدلی که کمترین Cp مالوس را داشته باشد 
مدل بهتری است 
بر اساس آن مدلی که دارای درجه ی آزادی 4 است به عنوان بهترین مدل شناخته میشود.

<p color = 'blue'>
با توجه به نمودار نیز میتوان به راحتی متوجه شد که در مرحله ی چهارم به مدل مناسب رسیده ایم.
</p>

</div>
